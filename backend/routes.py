# Enhanced routes.py - Building on your existing codebase
from flask import Blueprint, request, jsonify
import os
import logging
import uuid
import json
from datetime import datetime
import requests
from concurrent.futures import ThreadPoolExecutor
import time
import re
from bs4 import BeautifulSoup

# Import your existing modules
from agents.asi1_client import ask_asi1  # Your existing ASI1 integration
from agents.agentverse_client import create_agent, chat_with_agent  # Your existing agent code
from agents.trend_detector import TrendDetector  # Enhanced version

# Set up logging
logger = logging.getLogger(__name__)

# Create blueprint for routes
api = Blueprint('api', __name__)

# In-memory storage for jobs (enhance this with your Supabase later)
analysis_jobs = {}

def scrape_website_info(url: str) -> str:
    """Scrape basic info from website"""
    try:
        if not url.startswith('http'):
            url = f"https://{url}"
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(url, headers=headers, timeout=10)
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Extract title and meta description
            title = soup.find('title')
            title_text = title.get_text().strip() if title else ""
            
            meta_desc = soup.find('meta', attrs={'name': 'description'})
            desc_text = meta_desc.get('content', '').strip() if meta_desc else ""
            
            # Extract some text content (clean it up)
            for script in soup(["script", "style"]):
                script.decompose()
            text_content = soup.get_text()
            lines = (line.strip() for line in text_content.splitlines())
            chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
            text_content = ' '.join(chunk for chunk in chunks if chunk)[:500]
            
            # Extract keywords from content
            keywords = []
            if 'bakery' in text_content.lower() or 'bread' in text_content.lower() or 'cake' in text_content.lower():
                keywords.append('bakery')
            if 'restaurant' in text_content.lower() or 'food' in text_content.lower() or 'menu' in text_content.lower():
                keywords.append('restaurant') 
            if 'technology' in text_content.lower() or 'software' in text_content.lower() or 'app' in text_content.lower():
                keywords.append('technology')
            
            result = f"""Website Title: {title_text}
Meta Description: {desc_text}
Content Preview: {text_content}
Detected Keywords: {', '.join(keywords) if keywords else 'general business'}
URL Analyzed: {url}
Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}"""
            
            return result
        else:
            logger.warning(f"Website returned status {response.status_code}")
            return f"Website analysis failed: HTTP {response.status_code}"
        
    except Exception as e:
        logger.error(f"Enhanced agent creation error: {str(e)}")
        return jsonify({"error": str(e)}), 500



# Register all routes
def register_enhanced_routes(app):
    """Register enhanced routes with your existing Flask app"""
    app.register_blueprint(api, url_prefix='/api')
    logger.info("Enhanced routes registered - building on your existing codebase")

# Enhanced Multi-AI Client that works with your existing ASI1 integration
class EnhancedAIClient:
    """Enhanced AI client that builds on your existing ASI1 integration"""
    
    def __init__(self):
        self.groq_api_key = os.getenv('GROQ_API_KEY')
        self.anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')
        
        logger.info("Enhanced AI Client initialized")
        logger.info(f"Groq available: {bool(self.groq_api_key)}")
        logger.info(f"Anthropic available: {bool(self.anthropic_api_key)}")
    
    def ask_asi1_enhanced(self, prompt: str):
        """Use your existing ASI1 integration with enhancements"""
        try:
            # Use your existing ask_asi1 function
            response = ask_asi1(prompt)
            return {
                "response": response,
                "provider": "ASI1",
                "status": "success"
            }
        except Exception as e:
            logger.error(f"ASI1 error: {str(e)}")
            return {
                "response": f"ASI1 error: {str(e)}",
                "provider": "ASI1", 
                "status": "error"
            }
    
    def ask_groq_fast(self, prompt: str, max_tokens: int = 1000):
        """Fast processing with Groq"""
        if not self.groq_api_key:
            return {
                "response": "Groq API key not configured",
                "provider": "Groq",
                "status": "not_configured"
            }
        
        try:
            headers = {
                'Authorization': f'Bearer {self.groq_api_key}',
                'Content-Type': 'application/json'
            }
            
            data = {
                'model': 'llama3-70b-8192',
                'messages': [{'role': 'user', 'content': prompt}],
                'max_tokens': max_tokens,
                'temperature': 0.5
            }
            
            response = requests.post('https://api.groq.com/openai/v1/chat/completions', 
                                   headers=headers, json=data, timeout=20)
            
            if response.status_code == 200:
                result = response.json()
                return {
                    "response": result['choices'][0]['message']['content'],
                    "provider": "Groq",
                    "status": "success"
                }
            else:
                return {
                    "response": f"Groq API error: {response.status_code}",
                    "provider": "Groq",
                    "status": "error"
                }
                
        except Exception as e:
            logger.error(f"Groq request failed: {str(e)}")
            return {
                "response": f"Groq error: {str(e)}",
                "provider": "Groq",
                "status": "error"
            }
    
    def ask_anthropic_strategic(self, prompt: str, max_tokens: int = 2000):
        """Strategic analysis with Anthropic"""
        if not self.anthropic_api_key:
            return {
                "response": "Anthropic API key not configured",
                "provider": "Anthropic",
                "status": "not_configured"
            }
        
        try:
            headers = {
                'x-api-key': self.anthropic_api_key,
                'Content-Type': 'application/json',
                'anthropic-version': '2023-06-01'
            }
            
            data = {
                'model': 'claude-3-sonnet-20240229',
                'max_tokens': max_tokens,
                'messages': [{'role': 'user', 'content': prompt}]
            }
            
            response = requests.post('https://api.anthropic.com/v1/messages', 
                                   headers=headers, json=data, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                return {
                    "response": result['content'][0]['text'],
                    "provider": "Anthropic",
                    "status": "success"
                }
            else:
                return {
                    "response": f"Anthropic API error: {response.status_code}",
                    "provider": "Anthropic", 
                    "status": "error"
                }
                
        except Exception as e:
            logger.error(f"Anthropic request failed: {str(e)}")
            return {
                "response": f"Anthropic error: {str(e)}",
                "provider": "Anthropic",
                "status": "error"
            }

# Initialize enhanced AI client
enhanced_ai = EnhancedAIClient()

def extract_action_plan_from_ai(ai_response: str, business_name: str, categories: str) -> list:
    """Extract actionable items from AI response"""
    try:
        action_items = []
        lines = ai_response.split('\n')
        priority = 1
        
        # Look for action-oriented content
        for line in lines:
            line = line.strip()
            
            # Skip empty lines and headers
            if len(line) < 15 or line.startswith('#') or line.upper() == line:
                continue
                
            # Look for actionable content
            action_keywords = ['implement', 'create', 'develop', 'launch', 'optimize', 'build', 'establish', 'start', 'begin', 'setup', 'design', 'improve']
            
            if any(keyword in line.lower() for keyword in action_keywords):
                # Clean the line
                clean_line = re.sub(r'^[\d\.\-\*\#\s]+', '', line)
                clean_line = clean_line.replace('*', '').replace('#', '').strip()
                
                if len(clean_line) > 20 and len(clean_line) < 120:
                    # Extract ROI if mentioned in the line or nearby lines
                    roi_match = re.search(r'(\d+[-‚Äì]\d+%|\d+%)', line)
                    roi = roi_match.group(1) if roi_match else f"{120 + priority*30}-{180 + priority*40}%"
                    
                    # Extract timeline if mentioned
                    timeline_match = re.search(r'(\d+\s*(?:days?|weeks?|months?))', line.lower())
                    timeline = timeline_match.group(1) if timeline_match else f"{priority*30} days"
                    
                    # Create description
                    description = f"Strategic implementation for {business_name} in the {categories} sector"
                    
                    action_items.append({
                        "title": clean_line,
                        "priority": priority,
                        "timeline": timeline,
                        "roi_estimate": roi,
                        "description": description
                    })
                    
                    priority += 1
                    if len(action_items) >= 5:  # Get up to 5 items
                        break
        
        # If we didn't find enough items, look for any strategic content
        if len(action_items) < 3:
            for line in lines:
                line = line.strip()
                strategy_keywords = ['strategy', 'approach', 'plan', 'focus', 'target', 'utilize', 'leverage', 'enhance']
                
                if any(keyword in line.lower() for keyword in strategy_keywords) and len(line) > 20 and len(line) < 120:
                    clean_line = re.sub(r'^[\d\.\-\*\#\s]+', '', line)
                    clean_line = clean_line.replace('*', '').replace('#', '').strip()
                    
                    if clean_line and not any(item['title'] == clean_line for item in action_items):
                        action_items.append({
                            "title": clean_line,
                            "priority": len(action_items) + 1,
                            "timeline": f"{(len(action_items) + 1)*30} days",
                            "roi_estimate": f"{150 + len(action_items)*25}-{200 + len(action_items)*30}%",
                            "description": f"Strategic initiative for {business_name} in {categories}"
                        })
                        
                        if len(action_items) >= 3:
                            break
        
        # Fallback if still no items found
        if not action_items:
            action_items = [
                {
                    "title": f"Digital transformation strategy for {business_name}",
                    "priority": 1,
                    "timeline": "30 days",
                    "roi_estimate": "150-250%",
                    "description": f"Modernize digital presence and customer engagement for {categories} business"
                },
                {
                    "title": f"Customer acquisition optimization for {business_name}",
                    "priority": 2,
                    "timeline": "60 days",
                    "roi_estimate": "200-300%",
                    "description": f"Implement targeted marketing strategies for {categories} market"
                },
                {
                    "title": f"Operational efficiency enhancement for {business_name}",
                    "priority": 3,
                    "timeline": "90 days",
                    "roi_estimate": "120-220%",
                    "description": f"Streamline processes and reduce costs for {categories} operations"
                }
            ]
        
        return action_items[:3]  # Return top 3 items
        
    except Exception as e:
        logger.error(f"Error extracting action plan: {e}")
        return []

def extract_trends_from_ai(ai_response: str, categories: str) -> list:
    """Extract market trends from AI response"""
    trends = []
    lines = ai_response.split('\n')
    
    trend_keywords = ['trend', 'growing', 'increasing', 'emerging', 'rising', 'shift', 'change', 'evolution', 'adoption', 'transformation']
    
    for line in lines:
        line = line.strip()
        if any(keyword in line.lower() for keyword in trend_keywords):
            if len(line) > 25 and len(line) < 150:
                clean_trend = re.sub(r'^[\d\.\-\*\#\s]+', '', line)
                clean_trend = clean_trend.replace('*', '').replace('#', '').strip()
                
                if clean_trend and not clean_trend.startswith(('The ', 'A ', 'An ')):
                    trends.append(clean_trend)
    
    # Remove duplicates and keep unique trends
    unique_trends = []
    for trend in trends:
        if not any(similar_trend in trend.lower() or trend.lower() in similar_trend for similar_trend in unique_trends):
            unique_trends.append(trend)
    
    # Fallback trends if none found
    if not unique_trends:
        unique_trends = [
            f"Digital adoption accelerating across {categories} industry",
            f"Customer expectations evolving in {categories} market",
            f"Technology integration becoming essential for {categories} businesses"
        ]
    
    return unique_trends[:3]

def extract_opportunities_from_ai(ai_response: str, business_name: str, categories: str) -> list:
    """Extract opportunities from AI response"""
    opportunities = []
    lines = ai_response.split('\n')
    
    opp_keywords = ['opportunity', 'potential', 'gap', 'market', 'untapped', 'chance', 'opening', 'prospects', 'leverage', 'capitalize']
    
    for line in lines:
        line = line.strip()
        if any(keyword in line.lower() for keyword in opp_keywords):
            if len(line) > 25 and len(line) < 150:
                clean_opp = re.sub(r'^[\d\.\-\*\#\s]+', '', line)
                clean_opp = clean_opp.replace('*', '').replace('#', '').strip()
                
                if clean_opp and business_name.lower() not in clean_opp.lower():
                    # Add business context to opportunity
                    if not any(word in clean_opp.lower() for word in ['for', 'to']):
                        clean_opp = f"{clean_opp} for {business_name}"
                    opportunities.append(clean_opp)
    
    # Remove duplicates
    unique_opportunities = []
    for opp in opportunities:
        if not any(similar_opp in opp.lower() or opp.lower() in similar_opp for similar_opp in unique_opportunities):
            unique_opportunities.append(opp)
    
    # Fallback opportunities
    if not unique_opportunities:
        unique_opportunities = [
            f"Digital marketing expansion opportunities for {business_name}",
            f"Local market penetration strategies for {business_name}",
            f"Customer experience enhancement initiatives for {business_name}"
        ]
    
    return unique_opportunities[:3]

def extract_marketing_strategy_from_ai(ai_response: str, business_name: str) -> str:
    """Extract marketing strategy from AI response"""
    lines = ai_response.split('\n')
    strategy_keywords = ['marketing', 'strategy', 'approach', 'campaign', 'promotion', 'advertising', 'outreach']
    
    for i, line in enumerate(lines):
        if any(keyword in line.lower() for keyword in strategy_keywords):
            # Get this line and next few lines for context
            strategy_section = []
            for j in range(i, min(i + 4, len(lines))):
                clean_line = lines[j].strip().replace('*', '').replace('#', '')
                if clean_line and len(clean_line) > 10:
                    strategy_section.append(clean_line)
            
            if strategy_section:
                strategy = ' '.join(strategy_section)
                if len(strategy) > 60:
                    return strategy[:300] + "..." if len(strategy) > 300 else strategy
    
    return f"Implement comprehensive multi-channel marketing strategy for {business_name} focusing on digital transformation, customer acquisition, and brand building"

def extract_productivity_tips_from_ai(ai_response: str, categories: str) -> list:
    """Extract productivity tips from AI response"""
    tips = []
    lines = ai_response.split('\n')
    
    productivity_keywords = ['automate', 'efficiency', 'productivity', 'streamline', 'optimize', 'improve', 'enhance', 'system', 'process', 'workflow']
    
    for line in lines:
        line = line.strip()
        if any(keyword in line.lower() for keyword in productivity_keywords):
            if len(line) > 20 and len(line) < 120:
                clean_tip = re.sub(r'^[\d\.\-\*\#\s]+', '', line)
                clean_tip = clean_tip.replace('*', '').replace('#', '').strip()
                
                if clean_tip:
                    tips.append(clean_tip)
    
    # Remove duplicates
    unique_tips = []
    for tip in tips:
        if not any(similar_tip in tip.lower() or tip.lower() in similar_tip for similar_tip in unique_tips):
            unique_tips.append(tip)
    
    # Fallback tips
    if not unique_tips:
        unique_tips = [
            f"Implement automation tools for {categories} operations",
            f"Use data analytics to optimize {categories} performance",
            f"Streamline customer communication processes",
            f"Adopt cloud-based solutions for {categories} management",
            f"Create standardized workflows for {categories} tasks"
        ]
    
    return unique_tips[:5]

def extract_risk_assessment_from_ai(ai_response: str, business_name: str) -> str:
    """Extract risk assessment from AI response"""
    lines = ai_response.split('\n')
    risk_keywords = ['risk', 'challenge', 'threat', 'concern', 'issue', 'problem', 'barrier', 'obstacle']
    
    for line in lines:
        if any(keyword in line.lower() for keyword in risk_keywords):
            if len(line.strip()) > 30:
                clean_risk = line.strip().replace('*', '').replace('#', '')
                return clean_risk[:250] + "..." if len(clean_risk) > 250 else clean_risk
    
    return f"Moderate risk profile for {business_name} - success depends on proper strategy execution, market adaptation, and continuous performance monitoring"

def process_enhanced_analysis(job_id: str, business_data: dict):
    """Real AI-driven analysis with dynamic results"""
    try:
        analysis_jobs[job_id]["status"] = "processing"
        analysis_jobs[job_id]["progress"] = 10
        
        # Extract business data
        business_name = business_data.get('name', 'Unknown Business')
        website = business_data.get('website', '')
        categories = business_data.get('categories', 'general business')
        
        logger.info(f"üöÄ Starting REAL AI analysis for {business_name} in {categories}")
        
        # Step 1: Website analysis
        website_info = ""
        if website:
            logger.info(f"üîç Analyzing website: {website}")
            website_info = scrape_website_info(website)
            analysis_jobs[job_id]["progress"] = 20
        
        # Step 2: Industry analysis using TrendDetector
        logger.info(f"üìä Gathering market intelligence for {categories}")
        trend_detector = TrendDetector()
        market_trends = trend_detector.get_news_trends(categories, limit=5)
        industry_insights = trend_detector.get_industry_insights(categories, "small-medium")
        competitor_intel = trend_detector.get_competitor_intelligence(business_name, categories)
        
        analysis_jobs[job_id]["progress"] = 40
        
        # Step 3: Comprehensive AI analysis
        logger.info(f"ü§ñ Generating comprehensive analysis with ASI:One")
        comprehensive_prompt = f"""
You are a senior business consultant with 15+ years of experience analyzing {categories} businesses. Provide a detailed, actionable analysis for {business_name}.

BUSINESS CONTEXT:
- Business Name: {business_name}
- Industry: {categories}
- Website: {website}

WEBSITE ANALYSIS:
{website_info}

MARKET INTELLIGENCE:
{market_trends}

INDUSTRY INSIGHTS:
{industry_insights}

COMPETITOR INTELLIGENCE:
{competitor_intel}

ANALYSIS REQUIREMENTS:

1. BUSINESS ASSESSMENT:
Analyze {business_name} specifically in the {categories} market. Consider their positioning, strengths, and growth potential.

2. MARKET OPPORTUNITIES (Identify 3 specific opportunities):
- Opportunity 1: [Specific opportunity with ROI estimate and timeline]
- Opportunity 2: [Another opportunity with details]
- Opportunity 3: [Third opportunity with implementation notes]

3. ACTIONABLE MARKETING STRATEGIES (Provide 3 detailed strategies):
- Strategy 1: [Specific strategy with ROI estimate, timeline, and steps]
- Strategy 2: [Second strategy with measurable outcomes]
- Strategy 3: [Third strategy with resource requirements]

4. COMPETITIVE ADVANTAGES:
List 3 specific ways {business_name} can differentiate in the {categories} market.

5. PRODUCTIVITY IMPROVEMENTS:
Provide 5 specific productivity enhancements for {categories} businesses like {business_name}.

6. RISK ASSESSMENT:
Identify main risks for {business_name} in the {categories} industry and mitigation strategies.

7. IMPLEMENTATION ROADMAP:
30 days: [3 quick wins with specific actions]
60 days: [3 growth initiatives with metrics]
90 days: [3 scaling strategies with KPIs]

Focus on actionable, specific advice for {business_name}. Use concrete numbers, timelines, and ROI estimates where possible. Avoid generic recommendations.
"""
        
        analysis_jobs[job_id]["progress"] = 60
        
        # Step 4: Get AI analysis
        ai_analysis = enhanced_ai.ask_asi1_enhanced(comprehensive_prompt)
        analysis_jobs[job_id]["progress"] = 80
        
        # Step 5: Parse AI response and extract structured data
        ai_response = ai_analysis['response']
        logger.info(f"‚úÖ Received comprehensive analysis ({len(ai_response)} characters)")
        
        # Step 6: Extract structured data from AI response
        action_plan = extract_action_plan_from_ai(ai_response, business_name, categories)
        trends = extract_trends_from_ai(ai_response, categories)
        opportunities = extract_opportunities_from_ai(ai_response, business_name, categories)
        marketing_strategy = extract_marketing_strategy_from_ai(ai_response, business_name)
        productivity_tips = extract_productivity_tips_from_ai(ai_response, categories)
        risk_assessment = extract_risk_assessment_from_ai(ai_response, business_name)
        
        analysis_jobs[job_id]["progress"] = 95
        
        # Step 7: Format final results
        final_results = {
            "trends": trends,
            "opportunities": opportunities,
            "actionPlan": action_plan,
            "marketingStrategy": marketing_strategy,
            "competitiveAnalysis": f"AI-driven competitive analysis reveals {business_name} has strong potential in the {categories} market with proper strategic execution",
            "productivityTips": productivity_tips,
            "riskAssessment": risk_assessment,
            "analysis_details": {
                "ai_analysis": ai_response,
                "business_context": business_data,
                "website_info": website_info,
                "market_data": market_trends,
                "industry_insights": industry_insights,
                "competitor_intel": competitor_intel,
                "analysis_type": "comprehensive_ai_driven"
            },
            "metadata": {
                "timestamp": datetime.now().isoformat(),
                "ai_providers_used": [ai_analysis['provider']],
                "business_analyzed": business_name,
                "industry": categories,
                "website_analyzed": bool(website_info and "Website information not available" not in website_info),
                "analysis_method": "real_ai_parsing",
                "data_sources": "website_scraping + market_intelligence + ai_analysis"
            }
        }
        
        analysis_jobs[job_id]["results"] = final_results
        analysis_jobs[job_id]["status"] = "completed"
        analysis_jobs[job_id]["progress"] = 100
        
        logger.info(f"üéâ Comprehensive AI analysis completed for {business_name}")
        
    except Exception as e:
        logger.error(f"‚ùå Analysis failed for job {job_id}: {str(e)}")
        analysis_jobs[job_id]["status"] = "failed"
        analysis_jobs[job_id]["error"] = str(e)

# Your existing route enhanced
@api.route('/ask', methods=['POST'])
def enhanced_ask_route():
    """Enhanced version of your existing /ask route"""
    try:
        data = request.get_json()
        question = data.get('question', '')
        
        if not question:
            return jsonify({"error": "Question is required"}), 400
        
        # Use your existing ASI1 integration
        result = enhanced_ai.ask_asi1_enhanced(question)
        
        return jsonify({
            "response": result['response'],
            "provider": result['provider'],
            "status": result['status'],
            "enhanced": True
        })
        
    except Exception as e:
        logger.error(f"Enhanced ask route error: {str(e)}")
        return jsonify({"error": str(e)}), 500

# New enhanced routes building on your foundation
@api.route('/analyze', methods=['POST'])
def start_enhanced_analysis():
    """Enhanced business analysis using your existing code + new AIs"""
    try:
        data = request.get_json()
        
        if 'name' not in data:
            return jsonify({"error": "Business name is required"}), 400
        
        # Create analysis job
        job_id = str(uuid.uuid4())
        analysis_jobs[job_id] = {
            "status": "queued",
            "progress": 0,
            "created_at": datetime.now().isoformat(),
            "business_data": data,
            "type": "enhanced_business_analysis"
        }
        
        # Start background processing
        executor = ThreadPoolExecutor(max_workers=2)
        executor.submit(process_enhanced_analysis, job_id, data)
        
        return jsonify({
            "jobId": job_id,
            "message": "Enhanced business analysis started",
            "uses_your_existing_code": True,
            "estimated_completion": "2-3 minutes"
        })
        
    except Exception as e:
        logger.error(f"Enhanced analysis start error: {str(e)}")
        return jsonify({"error": str(e)}), 500

@api.route('/analyze/<job_id>/status', methods=['GET'])
def get_enhanced_status(job_id):
    """Get status of enhanced analysis"""
    if job_id not in analysis_jobs:
        return jsonify({"error": "Job not found"}), 404
    
    job = analysis_jobs[job_id]
    return jsonify({
        "status": job["status"],
        "progress": job["progress"],
        "created_at": job["created_at"],
        "type": job.get("type", "analysis"),
        "enhanced": True
    })

@api.route('/analyze/<job_id>/results', methods=['GET'])
def get_enhanced_results(job_id):
    """Get enhanced analysis results"""
    if job_id not in analysis_jobs:
        return jsonify({"error": "Job not found"}), 404
    
    job = analysis_jobs[job_id]
    
    if job["status"] != "completed":
        return jsonify({"error": "Analysis not completed yet", "status": job["status"]}), 400
    
    return jsonify(job["results"])

@api.route('/quick-insights', methods=['POST'])
def quick_business_insights():
    """Fast insights using Groq while preserving your ASI1 integration"""
    try:
        data = request.get_json()
        business_info = data.get('business_info', '')
        question = data.get('question', 'What are quick marketing opportunities?')
        
        prompt = f"""
        Business: {business_info}
        Question: {question}
        
        Provide 3-5 quick, actionable business insights for immediate implementation.
        Focus on marketing, productivity, and growth opportunities.
        """
        
        # Try Groq first for speed, fallback to your ASI1
        groq_result = enhanced_ai.ask_groq_fast(prompt, 500)
        
        if groq_result['status'] != 'success':
            # Fallback to your existing ASI1
            asi1_result = enhanced_ai.ask_asi1_enhanced(prompt)
            return jsonify({
                "insights": asi1_result['response'],
                "provider": asi1_result['provider'],
                "fallback_used": True,
                "response_time": "Using your existing ASI1 integration"
            })
        
        return jsonify({
            "insights": groq_result['response'],
            "provider": groq_result['provider'],
            "response_time": "< 5 seconds",
            "asi1_available": True
        })
        
    except Exception as e:
        logger.error(f"Quick insights error: {str(e)}")
        return jsonify({"error": str(e)}), 500

@api.route('/agent/create', methods=['POST'])
def create_enhanced_agent():
    """Enhanced version using your existing agent creation"""
    try:
        data = request.get_json()
        agent_name = data.get('name', f'agent_{uuid.uuid4().hex[:8]}')
        agent_seed = data.get('seed', str(uuid.uuid4()))
        
        # Use your existing create_agent function
        result = create_agent(agent_name, agent_seed)
        
        return jsonify({
            "agent": result,
            "enhanced": True,
            "uses_your_existing_code": True
        })
        
    except Exception as e:
        logger.error(f"Enhanced agent creation error: {str(e)}")
        return jsonify({"error": str(e)}), 500

@api.route('/agent/<agent_id>/chat', methods=['POST'])
def chat_enhanced_agent(agent_id):
    """Enhanced chat using your existing agent chat"""
    try:
        data = request.get_json()
        message = data.get('message', '')
        
        # Use your existing chat_with_agent function
        response = chat_with_agent(agent_id, message)
        
        return jsonify({
            "response": response,
            "agent_id": agent_id,
            "enhanced": True,
            "uses_your_existing_code": True
        })
        
    except Exception as e:
        logger.error(f"Enhanced agent chat error: {str(e)}")
        return jsonify({"error": str(e)}), 500

@api.route('/health', methods=['GET'])
def enhanced_health():
    """Enhanced health check showing your existing + new capabilities"""
    return jsonify({
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "your_existing_features": {
            "asi1_integration": "‚úÖ Working",
            "agent_system": "‚úÖ Enhanced", 
            "trend_detection": "‚úÖ Enhanced"
        },
        "new_enhancements": {
            "groq_integration": "‚úÖ" if enhanced_ai.groq_api_key else "‚ö†Ô∏è Not configured",
            "anthropic_integration": "‚úÖ" if enhanced_ai.anthropic_api_key else "‚ö†Ô∏è Not configured",
            "multi_ai_fallbacks": "‚úÖ Active",
            "business_intelligence": "‚úÖ Ready",
            "website_scraping": "‚úÖ Active",
            "ai_response_parsing": "‚úÖ Active"
        },
        "built_on_your_code": True
    })

